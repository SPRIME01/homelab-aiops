# ğŸ ğŸ¤– Homelab AIOps Platform

> **Unified Edge AI Operations Platform** - From data ingestion to model deployment, monitoring, and feedback loops - all orchestrated through a single, powerful monorepo.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Nx](https://img.shields.io/badge/built%20with-Nx-143055.svg)](https://nx.dev/)

---

## ğŸ¯ Vision

**Stop fighting fragmented AI toolchains.** Homelab AIOps unifies the entire ML lifecycleâ€”from data versioning to edge inferenceâ€”in a cohesive, Jetson-optimized platform that scales from your homelab to production fleets.

### ğŸª What Makes This Special?

- ğŸ”„ **End-to-End ML Lifecycle** - Data â†’ Training â†’ Deployment â†’ Monitoring â†’ Feedback
- ğŸš€ **Edge-First Design** - Optimized for NVIDIA Jetson Orin with sub-200ms inference
- ğŸ§© **Modular Architecture** - Swap backends, validators, or reward functions without breaking pipelines
- ğŸ“Š **Built-in Observability** - Comprehensive telemetry, tracing, and monitoring out-of-the-box
- ğŸ” **Automated Feedback Loops** - Human-in-the-loop training with automatic retraining triggers

---

## ğŸ—ï¸ Architecture Overview

```mermaid
graph TB
    subgraph "ğŸ  Homelab AIOps Platform"
        FS[ğŸ“Š Feature Store]
        ORCH[ğŸ­ Orchestrator]
        FT[ğŸ¯ Fine-Tuning]
        INFERENCE[âš¡ Inference/LiteLLM]
        PG[ğŸ§  Prompt Graph/DSPy]
        FB[ğŸ’¬ Feedback]
        TEL[ğŸ“ˆ Telemetry]
    end

    subgraph "ğŸ”§ Shared Infrastructure"
        LIBS[ğŸ“š Shared Libraries]
        TOOLS[ğŸ› ï¸ Tools & Scripts]
    end

    FS --> ORCH
    ORCH --> FT
    FT --> INFERENCE
    INFERENCE --> PG
    PG --> FB
    FB --> ORCH
    TEL --> ORCH

    LIBS -.-> FS
    LIBS -.-> ORCH
    LIBS -.-> FT
    LIBS -.-> INFERENCE
    LIBS -.-> PG
    LIBS -.-> FB
    LIBS -.-> TEL
```

---

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

Ensure you have these essentials installed:

- ğŸ **Python 3.11+** with `pyenv` for version management
- ğŸ“¦ **Node.js 20+** and `pnpm` (`npm install -g pnpm`)
- ğŸ”§ **GNU Make** (pre-installed on Linux/macOS, use WSL on Windows)
- ğŸ³ **Docker** (for containerization and deployment)
- ğŸ¯ **Git** (for version control)

### âš¡ One-Command Setup

```bash
# Clone and setup the entire platform
git clone https://github.com/SPRIME01/homelab-aiops.git
cd homelab-aiops
make setup
```

ğŸ‰ **That's it!** The setup command automatically:
- ğŸ”§ Initializes the Nx workspace with Python plugins
- ğŸ Sets up Python virtual environment with `pyenv` and `uv`
- ğŸ“ Installs pre-commit hooks for code quality
- ğŸ§© Configures custom generators for consistent project structure

---

## ğŸ® Daily Operations

### ğŸ†• Creating New Components

```bash
# Generate a new AI application
make app NAME=model-evaluator

# Generate a shared library
make lib NAME=inference-utils
```

### ğŸƒâ€â™‚ï¸ Development Workflow

```bash
# Lint all affected projects
make lint

# Type-check with mypy
make typecheck

# Run tests for changed code
make test

# Build affected projects
make build

# Serve a specific application locally
make serve PROJECT=inference
```

### ğŸ” Project Visualization

```bash
# Open interactive dependency graph
make graph
```

---

## ğŸ—ï¸ Platform Components

### ğŸ“Š **Feature Store** (`apps/feature-store`)
- ğŸ—„ï¸ Data ingestion and versioning
- ğŸ”„ ETL pipeline management
- ğŸ“ˆ Feature engineering and validation
- ğŸ” Data encryption and compliance

### ğŸ­ **Orchestrator** (`apps/orchestrator`)
- ğŸ”„ Pipeline coordination and scheduling
- ğŸ“‹ Workflow management with ZenML integration
- ğŸ“Š MLFlow experiment tracking
- ğŸš¨ Event-driven retraining triggers

### ğŸ¯ **Fine-Tuning** (`apps/fine-tuning`)
- ğŸš€ LlamaFactory integration for model training
- ğŸ“Š Experiment tracking and model comparison
- ğŸ† Automated model evaluation and selection
- ğŸ“¦ Model registry integration

### âš¡ **Inference** (`apps/inference/liteLLM`)
- ğŸ”€ LiteLLM routing to multiple backends
- ğŸ¥ Health checks and automatic failover
- ğŸ“ OpenAI-compatible API endpoints
- âš¡ Sub-200ms edge inference on Jetson

### ğŸ§  **Prompt Graph** (`apps/prompt-graph/dspy`)
- ğŸ¯ DSPy prompt optimization
- ğŸ“Š A/B testing for prompt performance
- ğŸ”„ Iterative improvement cycles
- ğŸ“ˆ Performance tracking and analytics

### ğŸ’¬ **Feedback** (`apps/feedback`)
- ğŸ‘¥ Human-in-the-loop feedback collection
- ğŸ”„ A/B testing interface
- ğŸ“Š Preference learning and RLHF
- ğŸ”” Automatic retraining triggers

### ğŸ“ˆ **Telemetry** (`apps/telemetry`)
- ğŸ“Š Prometheus metrics collection
- ğŸ“ Loki log aggregation
- ğŸ” Jaeger distributed tracing
- ğŸ“Š Grafana dashboards

---

## ğŸš€ Infrastructure & Deployment

### ğŸ—ï¸ Infrastructure as Code

```bash
# Plan infrastructure changes
make infra-plan TARGET=jetson-cluster

# Apply infrastructure
make infra-apply TARGET=jetson-cluster

# Run Ansible playbooks
make ansible-run PLAYBOOK=setup-jetson HOSTS=edge-nodes
```

### ğŸ³ Containerization

```bash
# Build Docker image for any service
make containerize PROJECT=inference

# Deploy to Kubernetes
make deploy-k8s-dev PROJECT=inference
```

---

## ğŸ¯ Key Features

### ğŸ”„ **Automated ML Lifecycle**
- ğŸ“Š **Data Versioning** with DVC integration
- ğŸ¯ **Model Training** via ZenML pipelines
- ğŸ“ˆ **Experiment Tracking** with MLFlow
- ğŸš€ **Auto-Deployment** of best models
- ğŸ“Š **Continuous Monitoring** and feedback

### âš¡ **Edge-Optimized Inference**
- ğŸ¯ **Jetson Optimization** with TensorRT quantization
- ğŸ”€ **Smart Routing** via LiteLLM
- ğŸ¥ **Health Monitoring** with automatic failover
- ğŸ“Š **Performance Tracking** (p95 < 200ms target)

### ğŸ§  **Intelligent Prompt Engineering**
- ğŸ¯ **DSPy Integration** for prompt optimization
- ğŸ“Š **A/B Testing** for prompt comparison
- ğŸ”„ **Iterative Improvement** cycles
- ğŸ“ˆ **Performance Analytics** and tracking

### ğŸ’¬ **Human-in-the-Loop Learning**
- ğŸ‘¥ **Feedback Collection** interfaces
- ğŸ† **Preference Learning** systems
- ğŸ”„ **RLHF Integration** pipelines
- ğŸš¨ **Auto-Retraining** triggers

---

## ğŸ› ï¸ Development Tools

### ğŸ **Python Toolchain**
- **pyenv** - Python version management
- **uv** - Lightning-fast dependency resolution
- **ruff** - High-performance linting and formatting
- **mypy** - Static type checking
- **pytest** - Comprehensive testing framework

### ğŸ”§ **Monorepo Management**
- **Nx** - Smart build system with dependency tracking
- **pnpm** - Efficient package management
- **Make** - Simple, powerful task orchestration
- **Pre-commit** - Automated code quality checks

---

## ğŸ“Š Monitoring & Observability

### ğŸ“ˆ **Metrics & Dashboards**
- ğŸ“Š **Prometheus** - Metrics collection and alerting
- ğŸ“Š **Grafana** - Beautiful, interactive dashboards
- ğŸ“ **Loki** - Log aggregation and search
- ğŸ” **Jaeger** - Distributed tracing

### ğŸš¨ **Alerting & SLAs**
- âš¡ **Inference Latency** - p95 < 200ms
- ğŸ¥ **Service Uptime** - 99.5% availability
- ğŸ”” **Pipeline Failures** - Slack notifications
- ğŸ“Š **Performance Degradation** - Automated alerts

---

## ğŸ”’ Security & Compliance

### ğŸ›¡ï¸ **Security Features**
- ğŸ” **Vault Integration** - Centralized secrets management
- ğŸŒ **Tailscale Mesh** - Secure network isolation
- ğŸ”‘ **TLS Everywhere** - End-to-end encryption
- ğŸ‘¥ **RBAC** - Role-based access control

### ğŸ“ **Compliance**
- ğŸš« **No PII** in training data
- ğŸ”’ **Data Encryption** at rest and in transit
- ğŸ“Š **Audit Logging** for all operations
- ğŸ” **Traceability** for every model and dataset

---

## ğŸ¯ Implementation Roadmap

| Priority | Feature | Status |
|----------|---------|--------|
| ğŸ”¥ **High** | Core Nx monorepo with apps | âœ… Complete |
| ğŸ”¥ **High** | Orchestrator + fine-tuning | ğŸš§ In Progress |
| ğŸ”¥ **High** | LiteLLM inference with health checks | ğŸ“‹ Planned |
| ğŸ”¶ **Medium** | Feature store + data versioning | ğŸ“‹ Planned |
| ğŸ”¶ **Medium** | DSPy prompt optimization | ğŸ“‹ Planned |
| ğŸ”¶ **Medium** | Telemetry and monitoring | ğŸ“‹ Planned |
| ğŸ”µ **Low** | Multi-cluster ArgoCD | ğŸ”® Future |
| ğŸ”µ **Low** | Advanced RLHF pipelines | ğŸ”® Future |

---

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### ğŸ§¹ Cleanup & Maintenance

```bash
# Clean all build artifacts and caches
make clean

# Reinstall everything
make setup
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- ğŸ§  **Nx Team** - For the amazing monorepo tooling
- ğŸ **Python Community** - For the incredible ecosystem
- ğŸ¤– **AI/ML Community** - For pushing the boundaries of what's possible
- ğŸ  **Homelab Community** - For inspiring self-hosted innovation

---

<div align="center">

**Built with â¤ï¸ for the AI-Native Future**

[Documentation](docs/) â€¢ [Issues](issues/) â€¢ [Discussions](discussions/)

</div>
